{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27021076",
   "metadata": {},
   "source": [
    "# T2-IA \n",
    "### Feito por chamada de API pela chave gratuita do Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbfba77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.187.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting pydantic (from google-generativeai)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting tqdm (from google-generativeai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-generativeai) (4.14.1)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyparsing<4,>=3.0.4 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->google-generativeai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic->google-generativeai)\n",
      "  Downloading pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic->google-generativeai)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
      "Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading grpcio-1.76.0-cp313-cp313-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading google_api_python_client-2.187.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: uritemplate, typing-inspection, tqdm, pyparsing, pydantic-core, pyasn1, protobuf, grpcio, cachetools, annotated-types, rsa, pydantic, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [google-generativeai]ogle-generativeai]language]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 cachetools-6.2.2 google-ai-generativelanguage-0.6.15 google-api-core-2.28.1 google-api-python-client-2.187.0 google-auth-2.43.0 google-auth-httplib2-0.2.1 google-generativeai-0.8.5 googleapis-common-protos-1.72.0 grpcio-1.76.0 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 protobuf-5.29.5 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.4 pydantic-core-2.41.5 pyparsing-3.2.5 rsa-4.9.1 tqdm-4.67.1 typing-inspection-0.4.2 uritemplate-4.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0d6746c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "46693c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "#modelo utilizado\n",
    "MODEL = \"gemini-2.5-flash\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64198489",
   "metadata": {},
   "source": [
    "## PROMPT ZERO SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7afbbbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 1\n",
      "Texto: Esse cara mentiu. Deixe eu falar pra vocês, esse cara mentiu sobre Ben Carson quando ele tirou os votos do Ben Carson em Iowa. E ele continua. Esse cara vai falar qualquer coisa. Cara nojento. Agora eu sei porque ele não tem patrocínios de nenhum dos seus colegas.\n",
      "Falácias: Ad Hominem, Generalização Apressada\n",
      "Resposta: Falacias: Ad Hominem, Generalização Apressada; Explicacao: O texto ataca a pessoa diretamente com insultos e alegações sobre seu caráter (\"nojento\", \"vai falar qualquer coisa\") em vez de seus argumentos (Ad Hominem). Também faz uma afirmação generalizada sobre o comportamento futuro da pessoa (\"Esse cara vai falar qualquer coisa\") baseada em incidentes passados (Generalização Apressada).\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 2\n",
      "Texto: Pessoa A: Acho que precisamos discutir formas de reduzir o número de armas em circulação no Brasil. Pessoa B: Então você quer desarmar completamente a população e deixar os cidadãos indefesos contra criminosos?\n",
      "Falácias: Falso Dilema, Apelo à Emoção, Espantalho\n",
      "Resposta: Falacias: Espantalho, Apelo à Emoção, Falso Dilema; Explicacao: Pessoa B distorce a proposta de Pessoa A para um extremo irrealista (Espantalho), usa linguagem que evoca medo para atacar a ideia distorcida (Apelo à Emoção) e apresenta essa distorção como a única consequência possível (Falso Dilema).\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 3\n",
      "Texto: Se você ama de verdade o Brasil e se importa com o futuro dos seus filhos, precisa protestar contra essa PEC que tenta blindar os parlamentares. Ficar calado agora é trair a nação e deixar que destruam o país.\n",
      "Falácias: Falso Dilema, Apelo à Emoção\n",
      "Resposta: Falacias: Apelo à Emoção, Falso Dilema; Explicacao: A frase apela para o amor ao Brasil e preocupação com os filhos (Apelo à Emoção) para pressionar o leitor, e apresenta apenas duas opções extremas (protestar ou trair a nação), ignorando outras possibilidades (Falso Dilema).\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 5\n",
      "Texto: Fui pra França no Natal, minha experiência lá com os franceses foi horrível. Até fui roubada quando visitei o museu do Louvre. Quando for pra Europa, saiba que a França é linda, mas os franceses são arrogantes e ladrões.\n",
      "Falácias: Generalização Apressada\n",
      "Resposta: Falacias: Generalização Apressada; Explicacao: O autor tira uma conclusão abrangente sobre todos os franceses (são arrogantes e ladrões) baseando-se em apenas uma experiência pessoal negativa e um único incidente de roubo.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 8\n",
      "Texto: Se começarmos a reduzir a jornada de trabalho e acabar com o regime 6x1, logo as empresas não vão conseguir se manter, o desemprego vai aumentar e a economia vai desabar\n",
      "Falácias: Ladeira Escorregadia, Apelo à Emoção\n",
      "Resposta: Falacias: Ladeira Escorregadia, Apelo à Emoção; Explicacao: O texto assume que uma pequena mudança levará inevitavelmente a uma série de consequências desastrosas (Ladeira Escorregadia) e usa o medo dessas consequências (desemprego, economia desabar) para persuadir (Apelo à Emoção).\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 12\n",
      "Texto: Quem defende que o governo deve investir mais em ciência está apenas querendo gastar dinheiro público sem retorno real.\n",
      "Falácias: Generalização Apressada, Espantalho\n",
      "Resposta: Falacias: Espantalho, Generalização Apressada; Explicacao: A fala distorce o argumento de quem defende investimento em ciência, atribuindo-lhes a intenção de apenas gastar dinheiro público sem retorno real (Espantalho), e generaliza essa motivação negativa para todo o grupo de defensores (Generalização Apressada).\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 14\n",
      "Texto: Ou você apoia a 'limpa' que foi feita no morro do Alemão ou está do lado dos criminosos que destroem famílias. Pense nas mães que perderam seus filhos! Quem se opõe a essa medida claramente não tem compaixão pelo sofrimento das reais vítimas.\n",
      "Falácias: Ad Hominem, Falso Dilema, Apelo à Emoção\n",
      "Resposta: Falacias: Falso Dilema, Apelo à Emoção, Ad Hominem; Explicacao: O texto apresenta um falso dilema ao propor apenas duas opções extremas. Faz um apelo à emoção ao invocar o sofrimento das mães para persuadir. Por fim, usa ad hominem ao desqualificar os oponentes por suposta falta de compaixão.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 17\n",
      "Texto: Quem critica a privatização é um preguiçoso que nunca produziu nada. Ou você apoia o livre mercado e o progresso, ou quer ver o país afundar na miséria.\n",
      "Falácias: Ad Hominem, Generalização Apressada, Falso Dilema, Apelo à Emoção\n",
      "Resposta: Falacias: Ad Hominem, Generalização Apressada, Falso Dilema, Apelo à Emoção; Explicacao: O texto ataca o caráter dos críticos, generaliza apressadamente sobre eles, apresenta apenas duas opções extremas como se fossem as únicas, e usa o medo para manipular a decisão.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 19\n",
      "Texto: Os acontecimentos no Nepal e agora no México mostram de forma clara que ou o Brasil regula as redes sociais ou seremos alvo de um golpe digital, tal qual está ocorrendo pelo mundo todo.\n",
      "Falácias: Ladeira Escorregadia, Generalização Apressada, Falso Dilema, Apelo à Emoção\n",
      "Resposta: Falacias: Falso Dilema, Generalização Apressada, Apelo à Emoção, Ladeira Escorregadia; Explicacao: O texto apresenta um falso dilema ao propor apenas duas opções extremas (regular as redes ou sofrer um golpe), faz uma generalização apressada ao concluir que um fenômeno é global baseado em apenas dois exemplos (Nepal e México), usa o apelo à emoção com o termo \"golpe digital\" para evocar medo e urgência, e emprega uma ladeira escorregadia ao afirmar que a falta de regulação levará inevitavelmente a essa catástrofe sem demonstrar a sequência lógica ou a inevitabilidade.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 20\n",
      "Texto: Pessoa A: Precisamos reduzir o consumo de carne para ajudar o planeta. Pessoa B: Então você quer acabar com os churrascos, fechar fazendas e destruir a economia rural? Se isso acontecer, o país vai quebrar.\n",
      "Falácias: Ladeira Escorregadia, Espantalho\n",
      "Resposta: Falacias: Espantalho, Ladeira Escorregadia; Explicacao: Pessoa B distorce a proposta de Pessoa A para uma versão exagerada e fácil de atacar (Espantalho) e, em seguida, argumenta que essa ação levará a uma série de consequências negativas extremas e inevitáveis (Ladeira Escorregadia).\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 33\n",
      "Texto: Pessoa A: acho que precisamos revisar impostos para empresas. Pessoa B: Então você quer destruir o empreendedorismo! E quem apoia isso claramente não tem compaixão pelos trabalhadores que dependem desses empregos.\n",
      "Falácias: Ad Hominem, Apelo à Emoção, Espantalho\n",
      "Resposta: Falacias: Espantalho, Apelo à Emoção, Ad Hominem; Explicacao: Pessoa B distorce a proposta de Pessoa A (\"revisar impostos\" vira \"destruir o empreendedorismo\"), apela às emoções com a menção de \"compaixão pelos trabalhadores\" e ataca o caráter de quem apoia a ideia, sugerindo falta de compaixão.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 37\n",
      "Texto: Se começarmos a liberar protestos em rodovias, logo ninguém conseguirá chegar ao trabalho. Eu vi *um* protesto que parou uma ambulância, então *todos* os protestos vão acabar matando gente.\n",
      "Falácias: Ladeira Escorregadia, Generalização Apressada\n",
      "Resposta: Falacias: Ladeira Escorregadia, Generalização Apressada; Explicacao: A primeira parte do texto argumenta que permitir protestos levará inevitavelmente a um cenário extremo de paralisação total (Ladeira Escorregadia). A segunda parte generaliza a partir de um único incidente específico (um protesto parando uma ambulância) para concluir que todos os protestos terão o mesmo resultado extremo (Generalização Apressada).\n",
      "===============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prompt_zero_shot(texto):\n",
    "    return f\"\"\"\n",
    "Tarefa: Identificar falácias lógicas em textos argumentativos.\n",
    "\n",
    "Instruções:\n",
    "Dado o texto abaixo, identifique quais as seguintes falácias estão presentes nele:\n",
    "- Ad Hominem\n",
    "- Ladeira Escorregadia\n",
    "- Generalização Apressada\n",
    "- Falso Dilema\n",
    "- Apelo à Emoção\n",
    "- Espantalho\n",
    "\n",
    "\n",
    "IMPORTANTE:\n",
    "- Use APENAS esses nomes de falácias, exatamente como escritos acima.\n",
    "- Se não tiver certeza, use apenas as falácias que mais se encaixam.\n",
    "- Produza a resposta em UMA ÚNICA LINHA, no seguinte formato:\n",
    "\n",
    "  Falacias: <lista de falácias separadas por vírgula>; Explicacao: <explicação curta em português>\n",
    "\n",
    "Exemplo de formato de saída:\n",
    "  Falacias: Ad Hominem, Falso Dilema; Explicacao: texto curto explicando por que essas falácias aparecem.\n",
    "\n",
    "Texto:\n",
    "\\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
    "\n",
    "Resposta:\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    model = genai.GenerativeModel(MODEL)\n",
    "    ids_escolhidos = [\"1\", \"2\", \"3\", \"5\", \"8\", \"12\", \"14\", \"17\", \"19\", \"20\", \"33\", \"37\"]\n",
    "    exemplos = []\n",
    "    falacias_lista = [\n",
    "    \"Ad Hominem\",\n",
    "    \"Ladeira Escorregadia\",\n",
    "    \"Generalização Apressada\",\n",
    "    \"Falso Dilema\",\n",
    "    \"Apelo à Emoção\",\n",
    "    \"Espantalho\"\n",
    "    ]\n",
    "\n",
    "    with open(\"../dataset_falacias_logicas.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for coluna in reader: \n",
    "            exemplos.append({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": coluna[\"texto\"]\n",
    "            })\n",
    "        exemplos = [c for c in exemplos if c[\"id\"] in ids_escolhidos]\n",
    "        shot_label = \"shot4\"\n",
    "        nome_arquivo = f\"zero_shot_respostas_{shot_label}.csv\"\n",
    "        caminho_arquivo = os.path.join(\"resultados\", nome_arquivo)\n",
    "\n",
    "        if not os.path.exists(\"resultados\"):\n",
    "            print(\"Pasta 'resultados/' não encontrada. Criando agora...\")\n",
    "            os.makedirs(\"resultados\")\n",
    "\n",
    "        if os.path.exists(caminho_arquivo): #verifica se o arquivo ja existe, se existir cria um com _novo, usamos isso pra testes com mesmo numero de shots pra ver o quanto variam as respostas\n",
    "            print(f\"Aviso: o arquivo {caminho_arquivo} já existe. Criando nova versão com final '_novo'.\")\n",
    "            base, ext = os.path.splitext(caminho_arquivo)\n",
    "            caminho_arquivo = base + \"_novo\" + ext\n",
    "\n",
    "    with open(caminho_arquivo, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "        writer = csv.DictWriter(f_out, fieldnames=[\"id\", \"texto\",\"falacias_encontradas\", \"resposta\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for coluna in exemplos:\n",
    "            texto = coluna[\"texto\"]\n",
    "            prompt = prompt_zero_shot(texto)\n",
    "            response = model.generate_content(prompt)\n",
    "            resposta_texto = \" \".join(response.text.split()).strip() #pra deixar formatado no csv\n",
    "            \n",
    "            #pra fazer a coluna de falacias encontradas no csv\n",
    "            falacias_encontradas = [f for f in falacias_lista if f.lower() in resposta_texto.lower()]\n",
    "            falacias_str = \", \".join(falacias_encontradas)\n",
    "            writer.writerow({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": texto,\n",
    "                \"falacias_encontradas\": falacias_str,\n",
    "                \"resposta\": resposta_texto\n",
    "            })\n",
    "            print(\"\\n===============================\")\n",
    "            print(f\"Feito teste zero-shot com texto ID: {coluna['id']}\")\n",
    "            print(f\"Texto: {texto}\")\n",
    "            print(f\"Falácias: {falacias_str if falacias_str else 'nenhuma detectada'}\")\n",
    "            print(f\"Resposta: {resposta_texto}\")\n",
    "            print(\"===============================\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e4a9f",
   "metadata": {},
   "source": [
    "## PROMPT FEW-SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a39adf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: o arquivo resultados/few_shot_respostas_shot2.csv já existe. Criando nova versão com final '_novo'.\n",
      "\n",
      "===== EXEMPLOS FEW-SHOT FORMATADOS =====\n",
      "Exemplo:\n",
      "Texto: \"Fui pra França no Natal, minha experiência lá com os franceses foi horrível. Até fui roubada quando visitei o museu do Louvre. Quando for pra Europa, saiba que a França é linda, mas os franceses são arrogantes e ladrões.\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Generalização Apressada; Explicacao: Generaliza a partir de poucos casos.\n",
      "\n",
      "Exemplo:\n",
      "Texto: \"Ou você apoia a reforma agraria, ou está contra o progresso e contra os direitos dos trabalhadores.\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Falso Dilema; Explicacao: Apresenta apenas duas opções extremas.\n",
      "\n",
      "Exemplo:\n",
      "Texto: \"As pessoas que criticam o uso de remédios naturais só querem vender mais remédios caros e não se preocupam com a saúde de verdade.\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Ad Hominem; Explicacao: Ataca motivação em vez de argumentar.\n",
      "\n",
      "Exemplo:\n",
      "Texto: \"Se aceitarmos que os esportes se tornem mais inclusivos para pessoas transgênero, logo todas as campeãs de competições femininas serão trans e as mulheres cisgênero não terão mais chance alguma de vencer\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Declive Escorregadio; Explicacao: Afirma que um passo leva ao extremo.\n",
      "\n",
      "Exemplo:\n",
      "Texto: \"Pessoa A: Acho que precisamos discutir limites para aluguel abusivo. Pessoa B: Ah, claro, você quer que ninguém mais possa alugar imóveis e destruir o mercado!\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Espantalho; Explicacao: Distorção extrema do argumento.\n",
      "\n",
      "Exemplo:\n",
      "Texto: \"Se você realmente ama sua família, vai apoiar este projeto de segurança. Não apoiar é abandonar quem você ama.\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Apelo à Emoção; Explicacao: Manipula culpa e medo.\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste few-shot com texto ID: 1\n",
      "Texto: Esse cara mentiu. Deixe eu falar pra vocês, esse cara mentiu sobre Ben Carson quando ele tirou os votos do Ben Carson em Iowa. E ele continua. Esse cara vai falar qualquer coisa. Cara nojento. Agora eu sei porque ele não tem patrocínios de nenhum dos seus colegas.\n",
      "Falácias: Ad Hominem\n",
      "Resposta: Falacias: Ad Hominem; Explicacao: Ataca o caráter da pessoa com insultos e desqualificações em vez de argumentos.\n",
      "===============================\n",
      "\n",
      "\n",
      "===== EXEMPLOS FEW-SHOT FORMATADOS =====\n",
      "Exemplo:\n",
      "Texto: \"Fui pra França no Natal, minha experiência lá com os franceses foi horrível. Até fui roubada quando visitei o museu do Louvre. Quando for pra Europa, saiba que a França é linda, mas os franceses são arrogantes e ladrões.\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Generalização Apressada; Explicacao: Generaliza a partir de poucos casos.\n",
      "\n",
      "Exemplo:\n",
      "Texto: \"Ou você apoia a reforma agraria, ou está contra o progresso e contra os direitos dos trabalhadores.\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Falso Dilema; Explicacao: Apresenta apenas duas opções extremas.\n",
      "\n",
      "Exemplo:\n",
      "Texto: \"As pessoas que criticam o uso de remédios naturais só querem vender mais remédios caros e não se preocupam com a saúde de verdade.\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Ad Hominem; Explicacao: Ataca motivação em vez de argumentar.\n",
      "\n",
      "Exemplo:\n",
      "Texto: \"Se aceitarmos que os esportes se tornem mais inclusivos para pessoas transgênero, logo todas as campeãs de competições femininas serão trans e as mulheres cisgênero não terão mais chance alguma de vencer\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Declive Escorregadio; Explicacao: Afirma que um passo leva ao extremo.\n",
      "\n",
      "Exemplo:\n",
      "Texto: \"Pessoa A: Acho que precisamos discutir limites para aluguel abusivo. Pessoa B: Ah, claro, você quer que ninguém mais possa alugar imóveis e destruir o mercado!\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Espantalho; Explicacao: Distorção extrema do argumento.\n",
      "\n",
      "Exemplo:\n",
      "Texto: \"Se você realmente ama sua família, vai apoiar este projeto de segurança. Não apoiar é abandonar quem você ama.\"\n",
      "Saída esperada (formato obrigatório):\n",
      "Falacias: Apelo à Emoção; Explicacao: Manipula culpa e medo.\n",
      "\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\nPlease retry in 12.906221316s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 250\n}\n, retry_delay {\n  seconds: 12\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m===============================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 106\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    104\u001b[39m texto = coluna[\u001b[33m\"\u001b[39m\u001b[33mtexto\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    105\u001b[39m prompt = prompt_few_shot(texto, exemplos_fewshot)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m resposta_texto = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(response.text.split()).strip()\n\u001b[32m    110\u001b[39m falacias_encontradas = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m falacias_lista \u001b[38;5;28;01mif\u001b[39;00m f.lower() \u001b[38;5;129;01min\u001b[39;00m resposta_texto.lower()]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/generativeai/generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:77\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\nPlease retry in 12.906221316s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 250\n}\n, retry_delay {\n  seconds: 12\n}\n]"
     ]
    }
   ],
   "source": [
    "def prompt_few_shot(texto, exemplos_fewshot):\n",
    "    exemplos_formatados = \"\"\n",
    "\n",
    "    # Exemplos few-shot já no formato desejado\n",
    "    for ex in exemplos_fewshot:\n",
    "        exemplos_formatados += (\n",
    "            \"Exemplo:\\n\"\n",
    "            f\"Texto: \\\"{ex['texto']}\\\"\\n\"\n",
    "            \"Saída esperada (formato obrigatório):\\n\"\n",
    "            f\"Falacias: {ex['falacia']}; \"\n",
    "            f\"Explicacao: {ex['resposta']}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # (Opcional) debug pra ver como ficou\n",
    "    print(\"\\n===== EXEMPLOS FEW-SHOT FORMATADOS =====\")\n",
    "    print(exemplos_formatados)\n",
    "    print(\"========================================\\n\")\n",
    "\n",
    "    return f\"\"\"\n",
    "Tarefa: Identificar falácias lógicas em textos argumentativos.\n",
    "\n",
    "A seguir estão alguns exemplos de como identificar falácias lógicas em textos,\n",
    "bem como o formato EXATO de saída que deve ser usado.\n",
    "\n",
    "{exemplos_formatados}\n",
    "Agora analise o próximo texto.\n",
    "\n",
    "Instruções gerais:\n",
    "Dado o texto abaixo, identifique quais das seguintes falácias estão presentes nele:\n",
    "- Ad Hominem\n",
    "- Ladeira Escorregadia\n",
    "- Generalização Apressada\n",
    "- Falso Dilema\n",
    "- Apelo à Emoção\n",
    "- Espantalho\n",
    "\n",
    "IMPORTANTE:\n",
    "- Use APENAS esses nomes de falácias, exatamente como escritos acima.\n",
    "- Se não tiver certeza, use apenas as falácias que mais se encaixam.\n",
    "- Produza a resposta em UMA ÚNICA LINHA, no seguinte formato:\n",
    "\n",
    "Agora, analise o seguinte texto:\n",
    "\n",
    "Texto:\n",
    "\\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
    "\n",
    "Resposta:\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    model = genai.GenerativeModel(MODEL)\n",
    "\n",
    "    ids_escolhidos = [\"1\", \"2\", \"3\", \"5\", \"8\", \"12\", \"14\", \"17\", \"19\", \"20\", \"33\", \"37\"]\n",
    "    exemplos = []\n",
    "    ids_exemplos_fewshot = [\"9\", \"11\", \"5\", \"6\", \"23\", \"22\"] #exemplos que irao ser usados no prompt few-shot\n",
    "    exemplos_fewshot = []\n",
    "\n",
    "    falacias_lista = [\n",
    "        \"Ad Hominem\",\n",
    "        \"Ladeira Escorregadia\",\n",
    "        \"Generalização Apressada\",\n",
    "        \"Falso Dilema\",\n",
    "        \"Apelo à Emoção\",\n",
    "        \"Espantalho\"\n",
    "    ]\n",
    "\n",
    "    #le csv\n",
    "    with open(\"../dataset_falacias_logicas.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for coluna in reader:\n",
    "            if coluna[\"id\"] in ids_exemplos_fewshot:\n",
    "                exemplos_fewshot.append({\n",
    "                    \"id\": coluna[\"id\"],\n",
    "                    \"texto\": coluna[\"texto\"],\n",
    "                    \"falacia\": coluna[\"falacias_esperadas\"], \n",
    "                    \"resposta\": coluna[\"resposta_esperada\"]\n",
    "                })\n",
    "\n",
    "            exemplos.append({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": coluna[\"texto\"]    \n",
    "            })\n",
    "\n",
    "        exemplos = [c for c in exemplos if c[\"id\"] in ids_escolhidos]\n",
    "\n",
    "        shot_label = \"shot2\"\n",
    "        nome_arquivo = f\"few_shot_respostas_{shot_label}.csv\"\n",
    "        caminho_arquivo = os.path.join(\"resultados\", nome_arquivo)\n",
    "\n",
    "        if not os.path.exists(\"resultados\"):\n",
    "            print(\"Pasta 'resultados/' não encontrada. Criando agora...\")\n",
    "            os.makedirs(\"resultados\")\n",
    "\n",
    "        if os.path.exists(caminho_arquivo):\n",
    "            print(f\"Aviso: o arquivo {caminho_arquivo} já existe. Criando nova versão com final '_novo'.\")\n",
    "            base, ext = os.path.splitext(caminho_arquivo)\n",
    "            caminho_arquivo = base + \"_novo\" + ext\n",
    "\n",
    "    with open(caminho_arquivo, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "        writer = csv.DictWriter(f_out, fieldnames=[\"id\", \"texto\", \"falacias_encontradas\", \"resposta\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for coluna in exemplos:\n",
    "            texto = coluna[\"texto\"]\n",
    "            prompt = prompt_few_shot(texto, exemplos_fewshot)\n",
    "            response = model.generate_content(prompt)\n",
    "\n",
    "            resposta_texto = \" \".join(response.text.split()).strip()\n",
    "\n",
    "            falacias_encontradas = [f for f in falacias_lista if f.lower() in resposta_texto.lower()]\n",
    "            falacias_str = \", \".join(falacias_encontradas)\n",
    "\n",
    "            writer.writerow({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": texto,\n",
    "                \"falacias_encontradas\": falacias_str,\n",
    "                \"resposta\": resposta_texto\n",
    "            })\n",
    "            print(\"\\n===============================\")\n",
    "            print(f\"Feito teste few-shot com texto ID: {coluna['id']}\")\n",
    "            print(f\"Texto: {texto}\")\n",
    "            print(f\"Falácias: {falacias_str if falacias_str else 'nenhuma detectada'}\")\n",
    "            print(f\"Resposta: {resposta_texto}\")\n",
    "            print(\"===============================\\n\")\n",
    "\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849fe8a",
   "metadata": {},
   "source": [
    "## PROMPT ZERO-SHOT-CHAIN-OF-THOUGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cfb335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 1\n",
      "Texto: Esse cara mentiu. Deixe eu falar pra vocês, esse cara mentiu sobre Ben Carson quando ele tirou os votos do Ben Carson em Iowa. E ele continua. Esse cara vai falar qualquer coisa. Cara nojento. Agora eu sei porque ele não tem patrocínios de nenhum dos seus colegas.\n",
      "Falácias: Ad Hominem, Generalização Apressada\n",
      "Resposta: Falacias: Ad Hominem, Generalização Apressada; Explicacao: O texto ataca o caráter da pessoa (\"Cara nojento\", \"Esse cara mentiu\") em vez de refutar seus argumentos (Ad Hominem) e faz uma generalização ampla sobre seu comportamento futuro (\"Esse cara vai falar qualquer coisa\") baseada em um número limitado de supostas ações passadas (Generalização Apressada).\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 2\n",
      "Texto: Pessoa A: Acho que precisamos discutir formas de reduzir o número de armas em circulação no Brasil. Pessoa B: Então você quer desarmar completamente a população e deixar os cidadãos indefesos contra criminosos?\n",
      "Falácias: Ladeira Escorregadia, Falso Dilema, Apelo à Emoção, Espantalho\n",
      "Resposta: Falacias: Espantalho, Ladeira Escorregadia, Apelo à Emoção, Falso Dilema; Explicacao: Pessoa B deturpa a proposta de Pessoa A ('discutir formas de reduzir') para uma versão extrema e mais fácil de atacar ('desarmar completamente'), criando um espantalho. Em seguida, alega que isso levará inevitavelmente a consequências negativas ('deixar os cidadãos indefesos contra criminosos'), configurando uma ladeira escorregadia. A frase 'deixar os cidadãos indefesos contra criminosos' apela à emoção (medo). A pergunta também impõe um falso dilema, sugerindo que só há duas opções extremas sem considerar alternativas.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 3\n",
      "Texto: Se você ama de verdade o Brasil e se importa com o futuro dos seus filhos, precisa protestar contra essa PEC que tenta blindar os parlamentares. Ficar calado agora é trair a nação e deixar que destruam o país.\n",
      "Falácias: Falso Dilema, Apelo à Emoção\n",
      "Resposta: Falacias: Apelo à Emoção, Falso Dilema; Explicacao: O texto usa termos como \"amar o Brasil\" e \"futuro dos filhos\" para manipular emoções, e apresenta apenas duas opções extremas (protestar ou trair a nação), ignorando outras possibilidades.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 5\n",
      "Texto: Fui pra França no Natal, minha experiência lá com os franceses foi horrível. Até fui roubada quando visitei o museu do Louvre. Quando for pra Europa, saiba que a França é linda, mas os franceses são arrogantes e ladrões.\n",
      "Falácias: Generalização Apressada\n",
      "Resposta: Falacias: Generalização Apressada; Explicacao: A pessoa generaliza a partir de uma experiência pessoal limitada e negativa para fazer uma afirmação abrangente e definitiva sobre todos os franceses.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 8\n",
      "Texto: Se começarmos a reduzir a jornada de trabalho e acabar com o regime 6x1, logo as empresas não vão conseguir se manter, o desemprego vai aumentar e a economia vai desabar\n",
      "Falácias: Ladeira Escorregadia\n",
      "Resposta: Falacias: Ladeira Escorregadia; Explicacao: O argumento sugere que uma ação inicial (redução da jornada de trabalho) levará inevitavelmente a uma série de consequências negativas extremas (desemprego, colapso econômico) sem evidências para cada passo.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 12\n",
      "Texto: Quem defende que o governo deve investir mais em ciência está apenas querendo gastar dinheiro público sem retorno real.\n",
      "Falácias: Ad Hominem, Espantalho\n",
      "Resposta: Falacias: Ad Hominem, Espantalho; Explicacao: A falácia Ad Hominem ataca a suposta motivação dos defensores do investimento em ciência (\"apenas querendo gastar dinheiro\") em vez de seus argumentos. A falácia do Espantalho distorce o argumento real para investir em ciência (que normalmente busca benefícios e retorno) para uma versão mais fraca e fácil de atacar (\"gastar dinheiro público sem retorno real\").\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 14\n",
      "Texto: Ou você apoia a 'limpa' que foi feita no morro do Alemão ou está do lado dos criminosos que destroem famílias. Pense nas mães que perderam seus filhos! Quem se opõe a essa medida claramente não tem compaixão pelo sofrimento das reais vítimas.\n",
      "Falácias: Ad Hominem, Falso Dilema, Apelo à Emoção\n",
      "Resposta: Falacias: Falso Dilema, Apelo à Emoção, Ad Hominem; Explicacao: O texto apresenta um falso dilema ao propor apenas duas opções extremas, apela à emoção ao invocar o sofrimento das mães e usa Ad Hominem ao atacar o caráter (falta de compaixão) de quem se opõe.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 17\n",
      "Texto: Quem critica a privatização é um preguiçoso que nunca produziu nada. Ou você apoia o livre mercado e o progresso, ou quer ver o país afundar na miséria.\n",
      "Falácias: Ad Hominem, Falso Dilema, Apelo à Emoção\n",
      "Resposta: Falacias: Ad Hominem, Falso Dilema, Apelo à Emoção; Explicacao: O texto ataca o caráter dos críticos em vez de seus argumentos (Ad Hominem), apresenta apenas duas opções extremas como se fossem as únicas (Falso Dilema), e usa o medo de ver o país afundar na miséria para manipular a escolha (Apelo à Emoção).\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 19\n",
      "Texto: Os acontecimentos no Nepal e agora no México mostram de forma clara que ou o Brasil regula as redes sociais ou seremos alvo de um golpe digital, tal qual está ocorrendo pelo mundo todo.\n",
      "Falácias: Generalização Apressada, Falso Dilema, Apelo à Emoção\n",
      "Resposta: Falacias: Falso Dilema, Generalização Apressada, Apelo à Emoção; Explicacao: O texto apresenta apenas duas opções extremas (Falso Dilema), generaliza uma ameaça global a partir de poucos exemplos (Generalização Apressada) e usa linguagem alarmista para evocar medo (\"golpe digital\") (Apelo à Emoção).\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 20\n",
      "Texto: Pessoa A: Precisamos reduzir o consumo de carne para ajudar o planeta. Pessoa B: Então você quer acabar com os churrascos, fechar fazendas e destruir a economia rural? Se isso acontecer, o país vai quebrar.\n",
      "Falácias: Ladeira Escorregadia, Apelo à Emoção, Espantalho\n",
      "Resposta: Falacias: Espantalho, Ladeira Escorregadia, Apelo à Emoção; Explicacao: Pessoa B distorce a proposta de Pessoa A para uma versão exagerada e fácil de atacar, argumentando que isso levará inevitavelmente a uma série de consequências desastrosas, visando provocar medo.\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 33\n",
      "Texto: Pessoa A: acho que precisamos revisar impostos para empresas. Pessoa B: Então você quer destruir o empreendedorismo! E quem apoia isso claramente não tem compaixão pelos trabalhadores que dependem desses empregos.\n",
      "Falácias: Ad Hominem, Apelo à Emoção, Espantalho\n",
      "Resposta: Falacias: Espantalho, Ad Hominem, Apelo à Emoção; Explicacao: Pessoa B distorce o argumento de Pessoa A para \"destruir o empreendedorismo\" (Espantalho), ataca o caráter de quem apoia a ideia (\"não tem compaixão\") (Ad Hominem) e tenta manipular a emoção usando a situação dos trabalhadores (Apelo à Emoção).\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "Feito teste zero-shot com texto ID: 37\n",
      "Texto: Se começarmos a liberar protestos em rodovias, logo ninguém conseguirá chegar ao trabalho. Eu vi *um* protesto que parou uma ambulância, então *todos* os protestos vão acabar matando gente.\n",
      "Falácias: Ladeira Escorregadia, Generalização Apressada\n",
      "Resposta: Falacias: Ladeira Escorregadia, Generalização Apressada; Explicacao: O texto assume uma sequência inevitável de eventos negativos a partir de uma ação inicial (Ladeira Escorregadia) e tira uma conclusão ampla sobre todos os protestos com base em um único incidente (Generalização Apressada).\n",
      "===============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prompt_zero_shot_CoT(texto):\n",
    "    return f\"\"\"\n",
    "Tarefa: Identificar falácias lógicas em textos argumentativos.\n",
    "\n",
    "Instruções:\n",
    "Dado o texto abaixo, identifique quais as seguintes falácias estão presentes nele:\n",
    "- Ad Hominem\n",
    "- Ladeira Escorregadia\n",
    "- Generalização Apressada\n",
    "- Falso Dilema\n",
    "- Apelo à Emoção\n",
    "- Espantalho\n",
    "\n",
    "Indique em uma linha de texto de no máximo 120 palavras a resposta que deve conter:\n",
    "- As falácias (nomes).\n",
    "- Indique em qual/quais trechos do texto argumentativo as falácias aparecem.\n",
    "- Dê uma breve explicação do por que aquele trecho representa essa falácia.\n",
    "\n",
    "Texto:\n",
    "\\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
    "\n",
    "Resposta: \n",
    "(Pense passo a passo para identificar, classificar e explicar as falácias presentes no texto acima.)\n",
    "(Mostre APENAS a resposta final, curta e organizada. Não revele o raciocínio.)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    model = genai.GenerativeModel(MODEL)\n",
    "    ids_escolhidos = [\"1\", \"2\", \"3\", \"5\", \"8\", \"12\", \"14\", \"17\", \"19\", \"20\", \"33\", \"37\"]\n",
    "    exemplos = []\n",
    "    falacias_lista = [\n",
    "    \"Ad Hominem\",\n",
    "    \"Ladeira Escorregadia\",\n",
    "    \"Generalização Apressada\",\n",
    "    \"Falso Dilema\",\n",
    "    \"Apelo à Emoção\",\n",
    "    \"Espantalho\"\n",
    "    ]\n",
    "\n",
    "    with open(\"../dataset_falacias_logicas.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for coluna in reader: \n",
    "            exemplos.append({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": coluna[\"texto\"]\n",
    "            })\n",
    "        exemplos = [c for c in exemplos if c[\"id\"] in ids_escolhidos]\n",
    "        shot_label = \"shot1\"\n",
    "        nome_arquivo = f\"zero_shot_cot_respostas_{shot_label}.csv\"\n",
    "        caminho_arquivo = os.path.join(\"resultados\", nome_arquivo)\n",
    "\n",
    "        if not os.path.exists(\"resultados\"):\n",
    "            print(\"Pasta 'resultados/' não encontrada. Criando agora...\")\n",
    "            os.makedirs(\"resultados\")\n",
    "\n",
    "        if os.path.exists(caminho_arquivo): #verifica se o arquivo ja existe, se existir cria um com _novo, usamos isso pra testes com mesmo numero de shots pra ver o quanto variam as respostas\n",
    "            print(f\"Aviso: o arquivo {caminho_arquivo} já existe. Criando nova versão com final '_novo'.\")\n",
    "            base, ext = os.path.splitext(caminho_arquivo)\n",
    "            caminho_arquivo = base + \"_novo\" + ext\n",
    "\n",
    "    with open(caminho_arquivo, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "        writer = csv.DictWriter(f_out, fieldnames=[\"id\", \"texto\",\"falacias_encontradas\", \"resposta\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for coluna in exemplos:\n",
    "            texto = coluna[\"texto\"]\n",
    "            prompt = prompt_zero_shot(texto)\n",
    "            response = model.generate_content(prompt)\n",
    "            resposta_texto = \" \".join(response.text.split()).strip() #pra deixar formatado no csv\n",
    "            \n",
    "            #pra fazer a coluna de falacias encontradas no csv\n",
    "            falacias_encontradas = [f for f in falacias_lista if f.lower() in resposta_texto.lower()]\n",
    "            falacias_str = \", \".join(falacias_encontradas)\n",
    "            writer.writerow({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": texto,\n",
    "                \"falacias_encontradas\": falacias_str,\n",
    "                \"resposta\": resposta_texto\n",
    "            })\n",
    "            print(\"\\n===============================\")\n",
    "            print(f\"Feito teste zero-shot com texto ID: {coluna['id']}\")\n",
    "            print(f\"Texto: {texto}\")\n",
    "            print(f\"Falácias: {falacias_str if falacias_str else 'nenhuma detectada'}\")\n",
    "            print(f\"Resposta: {resposta_texto}\")\n",
    "            print(\"===============================\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "727bc90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "FALACIA_COLS = [\n",
    "    \"ad_hominem\",\n",
    "    \"ladeira_escorregadia\",\n",
    "    \"gen_apressada\",\n",
    "    \"falso_dilema\",\n",
    "    \"apelo_emocao\",\n",
    "    \"espantalho\",\n",
    "]\n",
    "\n",
    "# mapeia pedaços de texto (em minúsculas) para a coluna correspondente\n",
    "KEYWORD_TO_COL = {\n",
    "    \"ad hominem\": \"ad_hominem\",\n",
    "    \"ladeira escorregadia\": \"ladeira_escorregadia\",\n",
    "    \"declive escorregadio\": \"ladeira_escorregadia\",  # sinônimo\n",
    "    \"generalização apressada\": \"gen_apressada\",\n",
    "    \"generalizacao apressada\": \"gen_apressada\",\n",
    "    \"falso dilema\": \"falso_dilema\",\n",
    "    \"apelo à emoção\": \"apelo_emocao\",\n",
    "    \"apelo a emoção\": \"apelo_emocao\",\n",
    "    \"apelo a emocao\": \"apelo_emocao\",\n",
    "    \"espantalho\": \"espantalho\",\n",
    "}\n",
    "\n",
    "def extrai_bins(falacias_str: str) -> dict:\n",
    "    #recebe string tipo 'Ad Hominem, Generalização Apressada e devolve como dicionario {col: 0/1}.\n",
    "    col_bins = {col: 0 for col in FALACIA_COLS}\n",
    "    if not falacias_str:\n",
    "        return col_bins\n",
    "\n",
    "    s = falacias_str.lower()\n",
    "\n",
    "    for key, col in KEYWORD_TO_COL.items():\n",
    "        if key in s:\n",
    "            col_bins[col] = 1\n",
    "\n",
    "    return col_bins\n",
    "\n",
    "\n",
    "def converte_resultado_para_binario(caminho_in, caminho_out=None):\n",
    "    #convertes os cvs resultados gerados pela ia pra binarios, pra comparar as falacias esperadas com as encontradas\n",
    "    if caminho_out is None:\n",
    "        base, ext = os.path.splitext(caminho_in)\n",
    "        caminho_out = base + \"_binario\" + ext\n",
    "\n",
    "    with open(caminho_in, newline=\"\", encoding=\"utf-8\") as f_in, \\\n",
    "         open(caminho_out, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "\n",
    "        reader = csv.DictReader(f_in)\n",
    "        fieldnames = [\"id\", \"texto\"] + FALACIA_COLS\n",
    "        writer = csv.DictWriter(f_out, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # opcional: debug pra ver colunas do csv de entrada\n",
    "        print(\"Colunas de entrada:\", reader.fieldnames)\n",
    "\n",
    "        for col in reader:\n",
    "            falacias_str = col.get(\"falacias_encontradas\", \"\")\n",
    "            bins = extrai_bins(falacias_str)\n",
    "\n",
    "            out_col = {\n",
    "                \"id\": col[\"id\"],\n",
    "                \"texto\": col[\"texto\"],\n",
    "            }\n",
    "            out_col.update(bins)\n",
    "            writer.writerow(out_col)\n",
    "\n",
    "    print(f\"Arquivo binário criado em: {caminho_out}\")\n",
    "    return caminho_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8111c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gabarito binário criado em: resultados/gabarito_binario_shot1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'resultados/gabarito_binario_shot1.csv'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "ids_escolhidos = [\"1\",\"2\",\"3\",\"5\",\"8\",\"12\",\"14\",\"17\",\"19\",\"20\",\"33\",\"37\"]\n",
    "\n",
    "def gerar_gabarito_binario(ids_escolhidos,caminho_dataset=\"../dataset_falacias_logicas.csv\",pasta_saida=\"resultados\",nome_base=\"gabarito_binario_shot1\"):\n",
    "    if not os.path.exists(pasta_saida):\n",
    "        os.makedirs(pasta_saida)\n",
    "\n",
    "    caminho_saida = os.path.join(pasta_saida, f\"{nome_base}.csv\")\n",
    "\n",
    "    fieldnames = [\n",
    "        \"id\", \"texto\",\n",
    "        \"ad_hominem\", \"ladeira_escorregadia\", \"gen_apressada\",\n",
    "        \"falso_dilema\", \"apelo_emocao\", \"espantalho\"\n",
    "    ]\n",
    "\n",
    "    with open(caminho_dataset, newline=\"\", encoding=\"utf-8\") as f_in:\n",
    "        reader = csv.DictReader(f_in)\n",
    "        with open(caminho_saida, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "            writer = csv.DictWriter(f_out, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for col in reader:\n",
    "                if col[\"id\"] in ids_escolhidos:\n",
    "                    writer.writerow({\n",
    "                        \"id\": col[\"id\"],\n",
    "                        \"texto\": col[\"texto\"],\n",
    "                        \"ad_hominem\": col[\"ad_hominem\"],\n",
    "                        \"ladeira_escorregadia\": col[\"ladeira_escorregadia\"],\n",
    "                        \"gen_apressada\": col[\"gen_apressada\"],\n",
    "                        \"falso_dilema\": col[\"falso_dilema\"],\n",
    "                        \"apelo_emocao\": col[\"apelo_emocao\"],\n",
    "                        \"espantalho\": col[\"espantalho\"],\n",
    "                    })\n",
    "\n",
    "    print(f\"Gabarito binário criado em: {caminho_saida}\")\n",
    "    return caminho_saida\n",
    "\n",
    "gerar_gabarito_binario(ids_escolhidos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af32b5",
   "metadata": {},
   "source": [
    "# Analise dos resultados obtidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#colunas binárias (iguais as do dataset_falacias_logicas.csv)\n",
    "FALACIA_COLS = [\n",
    "    \"ad_hominem\",\n",
    "    \"ladeira_escorregadia\",\n",
    "    \"gen_apressada\",\n",
    "    \"falso_dilema\",\n",
    "    \"apelo_emocao\",\n",
    "    \"espantalho\",\n",
    "]\n",
    "\n",
    "def carrega_gabarito_binario(caminho_dataset):\n",
    "    gabarito = {}\n",
    "    with open(caminho_dataset, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            gabarito[row[\"id\"]] = {col: int(row[col]) for col in FALACIA_COLS}\n",
    "    return gabarito\n",
    "\n",
    "def avalia_binario(caminho_resultado_bin, gabarito_bin):\n",
    "    precisions, recalls, f1s, exacts = [], [], [], []\n",
    "\n",
    "    with open(caminho_resultado_bin, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for col in reader:\n",
    "            id_ = col[\"id\"]\n",
    "            if id_ not in gabarito_bin:\n",
    "                continue  \n",
    "\n",
    "            #acabamos precisando de ajuda de IA pra modelar os resultados pra fazer os calculos e comparacoes\n",
    "            #usamos exact match como uma metrica adicional pra teste\n",
    "\n",
    "            y_true_dict = gabarito_bin[id_]\n",
    "            true_set = {c for c, v in y_true_dict.items() if v == 1}\n",
    "\n",
    "            y_pred_dict = {c: int(col[c]) for c in FALACIA_COLS}\n",
    "            pred_set = {c for c, v in y_pred_dict.items() if v == 1}\n",
    "\n",
    "            tp = len(true_set & pred_set)\n",
    "            fp = len(pred_set - true_set)\n",
    "            fn = len(true_set - pred_set)\n",
    "\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "            exact     = 1.0 if true_set == pred_set else 0.0\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            exacts.append(exact)\n",
    "\n",
    "    n = len(precisions) or 1\n",
    "    print(f\"\\n=== Avaliação: {caminho_resultado_bin} ===\")\n",
    "    print(f\"Precision médio: {sum(precisions)/n:.2f}\")\n",
    "    print(f\"Recall médio:    {sum(recalls)/n:.2f}\")\n",
    "    print(f\"F1 médio:        {sum(f1s)/n:.2f}\")\n",
    "    print(f\"Exact match:     {sum(exacts)/n:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97cff46",
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (1019872106.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\"\u001b[39m\n    ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "gabarito_bin = carrega_gabarito_binario(\"resultados/gabarito_binario_shot1.csv\")\n",
    "\"\"\"\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_respostas_shot1.csv\")\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_respostas_shot2.csv\")\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_respostas_shot3.csv\")\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_respostas_shot4.csv\")\n",
    "\n",
    "avalia_binario(\"resultados/zero_shot_respostas_shot1_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/zero_shot_respostas_shot2_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/zero_shot_respostas_shot3_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/zero_shot_respostas_shot4_binario.csv\", gabarito_bin)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "converte_resultado_para_binario(\"resultados/few_shot_respostas_shot1.csv\")\n",
    "converte_resultado_para_binario(\"resultados/few_shot_respostas_shot2.csv\")\n",
    "converte_resultado_para_binario(\"resultados/few_shot_respostas_shot3.csv\")\n",
    "converte_resultado_para_binario(\"resultados/few_shot_respostas_shot4.csv\")\n",
    "\n",
    "avalia_binario(\"resultados/few_shot_respostas_shot1_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/few_shot_respostas_shot2_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/few_shot_respostas_shot3_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/few_shot_respostas_shot4_binario.csv\", gabarito_bin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
