{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27021076",
   "metadata": {},
   "source": [
    "# T2-IA \n",
    "### Feito por chamada de API pela chave gratuita do Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfba77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46693c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "#tem que criar um arquivo .env com a chave da api pra executar ex: GEMINI_API_KEY=suachaveaqui \n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "#modelo utilizado\n",
    "MODEL = \"gemini-2.5-flash\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64198489",
   "metadata": {},
   "source": [
    "## PROMPT ZERO SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afbbbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_zero_shot(texto):\n",
    "    return f\"\"\"\n",
    "Tarefa: Identificar falácias lógicas em textos argumentativos.\n",
    "\n",
    "Instruções:\n",
    "Dado o texto abaixo, identifique quais as seguintes falácias estão presentes nele:\n",
    "- Ad Hominem\n",
    "- Ladeira Escorregadia\n",
    "- Generalização Apressada\n",
    "- Falso Dilema\n",
    "- Apelo à Emoção\n",
    "- Espantalho\n",
    "\n",
    "\n",
    "IMPORTANTE:\n",
    "- Use APENAS esses nomes de falácias, exatamente como escritos acima.\n",
    "- Se não tiver certeza, use apenas as falácias que mais se encaixam.\n",
    "- Produza a resposta em UMA ÚNICA LINHA, no seguinte formato:\n",
    "\n",
    "  Falacias: <lista de falácias separadas por vírgula>; Explicacao: <explicação curta em português>\n",
    "\n",
    "Exemplo de formato de saída:\n",
    "  Falacias: Ad Hominem, Falso Dilema; Explicacao: texto curto explicando por que essas falácias aparecem.\n",
    "\n",
    "Texto:\n",
    "\\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
    "\n",
    "Resposta:\n",
    "\"\"\"\n",
    "\n",
    "#modelo do zero shot, o modelo serve pros outros dois prompt tambem, principalmente a main\n",
    "\n",
    "def main():\n",
    "    model = genai.GenerativeModel(MODEL)\n",
    "    ids_escolhidos = [\"1\", \"2\", \"3\", \"5\", \"8\", \"12\", \"14\", \"17\", \"19\", \"20\", \"33\", \"37\"]\n",
    "    exemplos = []\n",
    "    falacias_lista = [\n",
    "    \"Ad Hominem\",\n",
    "    \"Ladeira Escorregadia\",\n",
    "    \"Generalização Apressada\",\n",
    "    \"Falso Dilema\",\n",
    "    \"Apelo à Emoção\",\n",
    "    \"Espantalho\"\n",
    "    ]\n",
    "\n",
    "    with open(\"../dataset_falacias_logicas.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for coluna in reader: \n",
    "            exemplos.append({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": coluna[\"texto\"]\n",
    "            })\n",
    "        exemplos = [c for c in exemplos if c[\"id\"] in ids_escolhidos]\n",
    "        shot_label = \"shot1\"\n",
    "        nome_arquivo = f\"zero_shot_respostas_{shot_label}.csv\"\n",
    "        caminho_arquivo = os.path.join(\"resultados\", nome_arquivo)\n",
    "\n",
    "        if not os.path.exists(\"resultados\"):\n",
    "            print(\"Pasta 'resultados/' não encontrada. Criando agora...\")\n",
    "            os.makedirs(\"resultados\")\n",
    "\n",
    "        if os.path.exists(caminho_arquivo): #verifica se o arquivo ja existe, se existir cria um com _novo, usamos isso pra testes com mesmo numero de shots pra ver o quanto variam as respostas\n",
    "            print(f\"Aviso: o arquivo {caminho_arquivo} já existe. Criando nova versão com final '_novo'.\")\n",
    "            base, ext = os.path.splitext(caminho_arquivo)\n",
    "            caminho_arquivo = base + \"_novo\" + ext #adiciona o novo e depois a gente só foi renomeando o arquivo pra qual shot era.\n",
    "\n",
    "    with open(caminho_arquivo, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "        writer = csv.DictWriter(f_out, fieldnames=[\"id\", \"texto\",\"falacias_encontradas\", \"resposta\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for coluna in exemplos:\n",
    "            texto = coluna[\"texto\"]\n",
    "            prompt = prompt_zero_shot(texto)\n",
    "            response = model.generate_content(prompt)\n",
    "            resposta_texto = \" \".join(response.text.split()).strip() #pra deixar formatado no csv\n",
    "            \n",
    "            #pra fazer a coluna de falacias encontradas no csv\n",
    "            falacias_encontradas = [f for f in falacias_lista if f.lower() in resposta_texto.lower()]\n",
    "            falacias_str = \", \".join(falacias_encontradas)\n",
    "            writer.writerow({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": texto,\n",
    "                \"falacias_encontradas\": falacias_str,\n",
    "                \"resposta\": resposta_texto\n",
    "            })\n",
    "            print(\"\\n===============================\")\n",
    "            print(f\"Feito teste zero-shot com texto ID: {coluna['id']}\")\n",
    "            print(f\"Texto: {texto}\")\n",
    "            print(f\"Falácias: {falacias_str if falacias_str else 'nenhuma detectada'}\")\n",
    "            print(f\"Resposta: {resposta_texto}\")\n",
    "            print(\"===============================\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e4a9f",
   "metadata": {},
   "source": [
    "## PROMPT FEW-SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39adf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_few_shot(texto, exemplos_fewshot):\n",
    "    exemplos_formatados = \"\"\n",
    "\n",
    "    #exemplos do few shot ja no formato certo\n",
    "    for ex in exemplos_fewshot:\n",
    "        exemplos_formatados += (\n",
    "            \"Exemplo:\\n\"\n",
    "            f\"Texto: \\\"{ex['texto']}\\\"\\n\"\n",
    "            \"Saída esperada (formato obrigatório):\\n\"\n",
    "            f\"Falacias: {ex['falacia']}; \"\n",
    "            f\"Explicacao: {ex['resposta']}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n===== EXEMPLOS FEW-SHOT FORMATADOS =====\")\n",
    "    print(exemplos_formatados)\n",
    "    print(\"========================================\\n\")\n",
    "\n",
    "    return f\"\"\"\n",
    "Tarefa: Identificar falácias lógicas em textos argumentativos.\n",
    "\n",
    "A seguir estão alguns exemplos de como identificar falácias lógicas em textos,\n",
    "bem como o formato EXATO de saída que deve ser usado.\n",
    "\n",
    "{exemplos_formatados}\n",
    "Agora analise o próximo texto.\n",
    "\n",
    "Instruções gerais:\n",
    "Dado o texto abaixo, identifique quais das seguintes falácias estão presentes nele:\n",
    "- Ad Hominem\n",
    "- Ladeira Escorregadia\n",
    "- Generalização Apressada\n",
    "- Falso Dilema\n",
    "- Apelo à Emoção\n",
    "- Espantalho\n",
    "\n",
    "IMPORTANTE:\n",
    "- Use APENAS esses nomes de falácias, exatamente como escritos acima.\n",
    "- Se não tiver certeza, use apenas as falácias que mais se encaixam.\n",
    "- Produza a resposta em UMA ÚNICA LINHA, no seguinte formato:\n",
    "\n",
    "Agora, analise o seguinte texto:\n",
    "\n",
    "Texto:\n",
    "\\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
    "\n",
    "Resposta:\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    model = genai.GenerativeModel(MODEL)\n",
    "\n",
    "    ids_escolhidos = [\"1\", \"2\", \"3\", \"5\", \"8\", \"12\", \"14\", \"17\", \"19\", \"20\", \"33\", \"37\"]\n",
    "    exemplos = []\n",
    "    ids_exemplos_fewshot = [\"9\", \"11\", \"5\", \"6\", \"23\", \"22\"] #exemplos que irao ser usados no prompt few-shot\n",
    "    exemplos_fewshot = []\n",
    "\n",
    "    falacias_lista = [\n",
    "        \"Ad Hominem\",\n",
    "        \"Ladeira Escorregadia\",\n",
    "        \"Generalização Apressada\",\n",
    "        \"Falso Dilema\",\n",
    "        \"Apelo à Emoção\",\n",
    "        \"Espantalho\"\n",
    "    ]\n",
    "\n",
    "    #le csv\n",
    "    with open(\"../dataset_falacias_logicas.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for coluna in reader:\n",
    "            if coluna[\"id\"] in ids_exemplos_fewshot:\n",
    "                exemplos_fewshot.append({\n",
    "                    \"id\": coluna[\"id\"],\n",
    "                    \"texto\": coluna[\"texto\"],\n",
    "                    \"falacia\": coluna[\"falacias_esperadas\"], \n",
    "                    \"resposta\": coluna[\"resposta_esperada\"]\n",
    "                })\n",
    "\n",
    "            exemplos.append({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": coluna[\"texto\"]    \n",
    "            })\n",
    "\n",
    "        exemplos = [c for c in exemplos if c[\"id\"] in ids_escolhidos]\n",
    "\n",
    "        shot_label = \"shot1\"\n",
    "        nome_arquivo = f\"few_shot_respostas_{shot_label}.csv\"\n",
    "        caminho_arquivo = os.path.join(\"resultados\", nome_arquivo)\n",
    "\n",
    "        if not os.path.exists(\"resultados\"):\n",
    "            print(\"Pasta 'resultados/' não encontrada. Criando agora...\")\n",
    "            os.makedirs(\"resultados\")\n",
    "\n",
    "        if os.path.exists(caminho_arquivo):\n",
    "            print(f\"Aviso: o arquivo {caminho_arquivo} já existe. Criando nova versão com final '_novo'.\")\n",
    "            base, ext = os.path.splitext(caminho_arquivo)\n",
    "            caminho_arquivo = base + \"_novo\" + ext\n",
    "\n",
    "    with open(caminho_arquivo, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "        writer = csv.DictWriter(f_out, fieldnames=[\"id\", \"texto\", \"falacias_encontradas\", \"resposta\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for coluna in exemplos:\n",
    "            texto = coluna[\"texto\"]\n",
    "            prompt = prompt_few_shot(texto, exemplos_fewshot)\n",
    "            response = model.generate_content(prompt)\n",
    "\n",
    "            resposta_texto = \" \".join(response.text.split()).strip()\n",
    "\n",
    "            falacias_encontradas = [f for f in falacias_lista if f.lower() in resposta_texto.lower()]\n",
    "            falacias_str = \", \".join(falacias_encontradas)\n",
    "\n",
    "            writer.writerow({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": texto,\n",
    "                \"falacias_encontradas\": falacias_str,\n",
    "                \"resposta\": resposta_texto\n",
    "            })\n",
    "            print(\"\\n===============================\")\n",
    "            print(f\"Feito teste few-shot com texto ID: {coluna['id']}\")\n",
    "            print(f\"Texto: {texto}\")\n",
    "            print(f\"Falácias: {falacias_str if falacias_str else 'nenhuma detectada'}\")\n",
    "            print(f\"Resposta: {resposta_texto}\")\n",
    "            print(\"===============================\\n\")\n",
    "\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849fe8a",
   "metadata": {},
   "source": [
    "## PROMPT ZERO-SHOT-CHAIN-OF-THOUGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cfb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_zero_shot_CoT(texto):\n",
    "    return f\"\"\"\n",
    "Tarefa: Identificar falácias lógicas em textos argumentativos.\n",
    "\n",
    "Instruções:\n",
    "Dado o texto abaixo, identifique quais as seguintes falácias estão presentes nele:\n",
    "- Ad Hominem\n",
    "- Ladeira Escorregadia\n",
    "- Generalização Apressada\n",
    "- Falso Dilema\n",
    "- Apelo à Emoção\n",
    "- Espantalho\n",
    "\n",
    "Indique em uma linha de texto de no máximo 120 palavras a resposta que deve conter:\n",
    "- As falácias (nomes).\n",
    "- Indique em qual/quais trechos do texto argumentativo as falácias aparecem.\n",
    "- Dê uma breve explicação do por que aquele trecho representa essa falácia.\n",
    "\n",
    "Texto:\n",
    "\\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
    "\n",
    "Resposta: \n",
    "(Pense passo a passo para identificar, classificar e explicar as falácias presentes no texto acima.)\n",
    "(Mostre APENAS a resposta final, curta e organizada. Não revele o raciocínio.)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    model = genai.GenerativeModel(MODEL)\n",
    "    ids_escolhidos = [\"1\", \"2\", \"3\", \"5\", \"8\", \"12\", \"14\", \"17\", \"19\", \"20\", \"33\", \"37\"]\n",
    "    exemplos = []\n",
    "    falacias_lista = [\n",
    "    \"Ad Hominem\",\n",
    "    \"Ladeira Escorregadia\",\n",
    "    \"Generalização Apressada\",\n",
    "    \"Falso Dilema\",\n",
    "    \"Apelo à Emoção\",\n",
    "    \"Espantalho\"\n",
    "    ]\n",
    "\n",
    "    with open(\"../dataset_falacias_logicas.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for coluna in reader: \n",
    "            exemplos.append({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": coluna[\"texto\"]\n",
    "            })\n",
    "        exemplos = [c for c in exemplos if c[\"id\"] in ids_escolhidos]\n",
    "        shot_label = \"shot1\"\n",
    "        nome_arquivo = f\"zero_shot_cot_respostas_{shot_label}.csv\"\n",
    "        caminho_arquivo = os.path.join(\"resultados\", nome_arquivo)\n",
    "\n",
    "        if not os.path.exists(\"resultados\"):\n",
    "            print(\"Pasta 'resultados/' não encontrada. Criando agora...\")\n",
    "            os.makedirs(\"resultados\")\n",
    "\n",
    "        if os.path.exists(caminho_arquivo): #verifica se o arquivo ja existe, se existir cria um com _novo, usamos isso pra testes com mesmo numero de shots pra ver o quanto variam as respostas\n",
    "            print(f\"Aviso: o arquivo {caminho_arquivo} já existe. Criando nova versão com final '_novo'.\")\n",
    "            base, ext = os.path.splitext(caminho_arquivo)\n",
    "            caminho_arquivo = base + \"_novo\" + ext\n",
    "\n",
    "    with open(caminho_arquivo, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "        writer = csv.DictWriter(f_out, fieldnames=[\"id\", \"texto\",\"falacias_encontradas\", \"resposta\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for coluna in exemplos:\n",
    "            texto = coluna[\"texto\"]\n",
    "            prompt = prompt_zero_shot(texto)\n",
    "            response = model.generate_content(prompt)\n",
    "            resposta_texto = \" \".join(response.text.split()).strip() #pra deixar formatado no csv\n",
    "            \n",
    "            #pra fazer a coluna de falacias encontradas no csv\n",
    "            falacias_encontradas = [f for f in falacias_lista if f.lower() in resposta_texto.lower()]\n",
    "            falacias_str = \", \".join(falacias_encontradas)\n",
    "            writer.writerow({\n",
    "                \"id\": coluna[\"id\"],\n",
    "                \"texto\": texto,\n",
    "                \"falacias_encontradas\": falacias_str,\n",
    "                \"resposta\": resposta_texto\n",
    "            })\n",
    "            print(\"\\n===============================\")\n",
    "            print(f\"Feito teste zero-shot com texto ID: {coluna['id']}\")\n",
    "            print(f\"Texto: {texto}\")\n",
    "            print(f\"Falácias: {falacias_str if falacias_str else 'nenhuma detectada'}\")\n",
    "            print(f\"Resposta: {resposta_texto}\")\n",
    "            print(\"===============================\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bc90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "FALACIA_COLS = [\n",
    "    \"ad_hominem\",\n",
    "    \"ladeira_escorregadia\",\n",
    "    \"gen_apressada\",\n",
    "    \"falso_dilema\",\n",
    "    \"apelo_emocao\",\n",
    "    \"espantalho\",\n",
    "]\n",
    "\n",
    "#mapeia pedaços de texto (em minúsculas) para a coluna correspondente\n",
    "KEYWORD_TO_COL = {\n",
    "    \"ad hominem\": \"ad_hominem\",\n",
    "    \"ladeira escorregadia\": \"ladeira_escorregadia\",\n",
    "    \"declive escorregadio\": \"ladeira_escorregadia\",  # sinônimo\n",
    "    \"generalização apressada\": \"gen_apressada\",\n",
    "    \"generalizacao apressada\": \"gen_apressada\",\n",
    "    \"falso dilema\": \"falso_dilema\",\n",
    "    \"apelo à emoção\": \"apelo_emocao\",\n",
    "    \"apelo a emoção\": \"apelo_emocao\",\n",
    "    \"apelo a emocao\": \"apelo_emocao\",\n",
    "    \"espantalho\": \"espantalho\",\n",
    "}\n",
    "\n",
    "def extrai_bins(falacias_str: str) -> dict:\n",
    "    #recebe string tipo 'Ad Hominem, Generalização Apressada e devolve como dicionario {col: 0/1}.\n",
    "    col_bins = {col: 0 for col in FALACIA_COLS}\n",
    "    if not falacias_str:\n",
    "        return col_bins\n",
    "\n",
    "    s = falacias_str.lower()\n",
    "\n",
    "    for key, col in KEYWORD_TO_COL.items():\n",
    "        if key in s:\n",
    "            col_bins[col] = 1\n",
    "\n",
    "    return col_bins\n",
    "\n",
    "\n",
    "def converte_resultado_para_binario(caminho_in, caminho_out=None):\n",
    "    #convertes os cvs resultados gerados pela ia pra binarios, pra comparar as falacias esperadas com as encontradas\n",
    "    if caminho_out is None:\n",
    "        base, ext = os.path.splitext(caminho_in)\n",
    "        caminho_out = base + \"_binario\" + ext\n",
    "\n",
    "    with open(caminho_in, newline=\"\", encoding=\"utf-8\") as f_in, \\\n",
    "         open(caminho_out, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "\n",
    "        reader = csv.DictReader(f_in)\n",
    "        fieldnames = [\"id\", \"texto\"] + FALACIA_COLS\n",
    "        writer = csv.DictWriter(f_out, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # opcional: debug pra ver colunas do csv de entrada\n",
    "        print(\"Colunas de entrada:\", reader.fieldnames)\n",
    "\n",
    "        for col in reader:\n",
    "            falacias_str = col.get(\"falacias_encontradas\", \"\")\n",
    "            bins = extrai_bins(falacias_str)\n",
    "\n",
    "            out_col = {\n",
    "                \"id\": col[\"id\"],\n",
    "                \"texto\": col[\"texto\"],\n",
    "            }\n",
    "            out_col.update(bins)\n",
    "            writer.writerow(out_col)\n",
    "\n",
    "    print(f\"Arquivo binário criado em: {caminho_out}\")\n",
    "    return caminho_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8111c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "ids_escolhidos = [\"1\",\"2\",\"3\",\"5\",\"8\",\"12\",\"14\",\"17\",\"19\",\"20\",\"33\",\"37\"]\n",
    "\n",
    "def gerar_gabarito_binario(ids_escolhidos,caminho_dataset=\"../dataset_falacias_logicas.csv\",pasta_saida=\"resultados\",nome_base=\"gabarito_binario_shot1\"):\n",
    "    if not os.path.exists(pasta_saida):\n",
    "        os.makedirs(pasta_saida)\n",
    "\n",
    "    caminho_saida = os.path.join(pasta_saida, f\"{nome_base}.csv\")\n",
    "\n",
    "    fieldnames = [\n",
    "        \"id\", \"texto\",\n",
    "        \"ad_hominem\", \"ladeira_escorregadia\", \"gen_apressada\",\n",
    "        \"falso_dilema\", \"apelo_emocao\", \"espantalho\"\n",
    "    ]\n",
    "\n",
    "    with open(caminho_dataset, newline=\"\", encoding=\"utf-8\") as f_in:\n",
    "        reader = csv.DictReader(f_in)\n",
    "        with open(caminho_saida, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "            writer = csv.DictWriter(f_out, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for col in reader:\n",
    "                if col[\"id\"] in ids_escolhidos:\n",
    "                    writer.writerow({\n",
    "                        \"id\": col[\"id\"],\n",
    "                        \"texto\": col[\"texto\"],\n",
    "                        \"ad_hominem\": col[\"ad_hominem\"],\n",
    "                        \"ladeira_escorregadia\": col[\"ladeira_escorregadia\"],\n",
    "                        \"gen_apressada\": col[\"gen_apressada\"],\n",
    "                        \"falso_dilema\": col[\"falso_dilema\"],\n",
    "                        \"apelo_emocao\": col[\"apelo_emocao\"],\n",
    "                        \"espantalho\": col[\"espantalho\"],\n",
    "                    })\n",
    "\n",
    "    print(f\"Gabarito binário criado em: {caminho_saida}\")\n",
    "    return caminho_saida\n",
    "\n",
    "gerar_gabarito_binario(ids_escolhidos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af32b5",
   "metadata": {},
   "source": [
    "# Analise dos resultados obtidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#colunas binárias \n",
    "FALACIA_COLS = [\n",
    "    \"ad_hominem\",\n",
    "    \"ladeira_escorregadia\",\n",
    "    \"gen_apressada\",\n",
    "    \"falso_dilema\",\n",
    "    \"apelo_emocao\",\n",
    "    \"espantalho\",\n",
    "]\n",
    "\n",
    "def carrega_gabarito_binario(caminho_dataset):\n",
    "    gabarito = {}\n",
    "    with open(caminho_dataset, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            gabarito[row[\"id\"]] = {col: int(row[col]) for col in FALACIA_COLS}\n",
    "    return gabarito\n",
    "\n",
    "def avalia_binario(caminho_resultado_bin, gabarito_bin):\n",
    "    precisions, recalls, f1s, exacts = [], [], [], []\n",
    "\n",
    "    with open(caminho_resultado_bin, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for col in reader:\n",
    "            id_ = col[\"id\"]\n",
    "            if id_ not in gabarito_bin:\n",
    "                continue  \n",
    "\n",
    "            #acabamos precisando de ajuda de IA pra modelar os resultados pra fazer os calculos e comparacoes\n",
    "            #usamos exact match como uma metrica adicional pra teste\n",
    "\n",
    "            y_true_dict = gabarito_bin[id_]\n",
    "            true_set = {c for c, v in y_true_dict.items() if v == 1}\n",
    "\n",
    "            y_pred_dict = {c: int(col[c]) for c in FALACIA_COLS}\n",
    "            pred_set = {c for c, v in y_pred_dict.items() if v == 1}\n",
    "\n",
    "            tp = len(true_set & pred_set)\n",
    "            fp = len(pred_set - true_set)\n",
    "            fn = len(true_set - pred_set)\n",
    "\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "            exact     = 1.0 if true_set == pred_set else 0.0\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            exacts.append(exact)\n",
    "\n",
    "    n = len(precisions) or 1\n",
    "    print(f\"\\n=== Avaliação: {caminho_resultado_bin} ===\")\n",
    "    print(f\"Precision médio: {sum(precisions)/n:.2f}\")\n",
    "    print(f\"Recall médio:    {sum(recalls)/n:.2f}\")\n",
    "    print(f\"F1 médio:        {sum(f1s)/n:.2f}\")\n",
    "    print(f\"Exact match:     {sum(exacts)/n:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97cff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gabarito_bin = carrega_gabarito_binario(\"resultados/gabarito_binario_shot1.csv\")\n",
    "\"\"\"\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_respostas_shot1.csv\")\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_respostas_shot2.csv\")\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_respostas_shot3.csv\")\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_respostas_shot4.csv\")\n",
    "\n",
    "avalia_binario(\"resultados/zero_shot_respostas_shot1_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/zero_shot_respostas_shot2_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/zero_shot_respostas_shot3_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/zero_shot_respostas_shot4_binario.csv\", gabarito_bin)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "converte_resultado_para_binario(\"resultados/few_shot_respostas_shot1.csv\")\n",
    "converte_resultado_para_binario(\"resultados/few_shot_respostas_shot2.csv\")\n",
    "converte_resultado_para_binario(\"resultados/few_shot_respostas_shot3.csv\")\n",
    "converte_resultado_para_binario(\"resultados/few_shot_respostas_shot4.csv\")\n",
    "\n",
    "avalia_binario(\"resultados/few_shot_respostas_shot1_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/few_shot_respostas_shot2_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/few_shot_respostas_shot3_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/few_shot_respostas_shot4_binario.csv\", gabarito_bin)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_cot_respostas_shot1.csv\")\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_cot_respostas_shot2.csv\")\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_cot_respostas_shot3.csv\")\n",
    "converte_resultado_para_binario(\"resultados/zero_shot_cot_respostas_shot4.csv\")\n",
    "\n",
    "avalia_binario(\"resultados/zero_shot_cot_respostas_shot1_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/zero_shot_cot_respostas_shot2_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/zero_shot_cot_respostas_shot3_binario.csv\", gabarito_bin)\n",
    "avalia_binario(\"resultados/zero_shot_cot_respostas_shot4_binario.csv\", gabarito_bin)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
